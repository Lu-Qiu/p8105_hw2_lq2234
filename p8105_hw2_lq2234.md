Homework 2
================
Lu Qiu
2023-09-27

``` r
library(tidyverse)
library(readxl)
```

### Problem 1

First, clean the data in pols-month.csv.

``` r
pols_month = 
  read_csv('./data/pols-month.csv') |>
  janitor::clean_names() |>
  separate(mon, into = c('year', 'month', 'day'), sep = '-') |>
  mutate(
    year = as.numeric(year)
  ) |>
  mutate(
    month = case_match(
      month,
      '01' ~ 'January',
      '02' ~ 'February',
      '03' ~ 'March',
      '04' ~ 'April',
      '05' ~ 'May',
      '06' ~ 'June',
      '07' ~ 'July',
      '08' ~ 'August',
      '09' ~ 'September',
      '10' ~ 'October',
      '11' ~ 'November',
      '12' ~ 'December'
    )) |>
  mutate(
    president = case_match(
      prez_dem,
      1  ~ 'dem',
      0 ~ 'gop'
    )) |>
  select(-c(prez_dem, prez_gop, day))
```

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp_df = 
  read_csv('./data/snp.csv') |>
  janitor::clean_names() |>
  mutate(
    date = as.Date(date, format = '%m/%d/%y')
  ) |>
  mutate(
    date = as.Date(ifelse(date > Sys.Date(),
                           format(date, '19%y-%m-%d'),
                           format(date)))
  ) |>
  separate(date, into = c('year', 'month', 'day'), sep = '-') |>
  mutate(
    year = as.numeric(year)
  ) |>
  mutate(
    month = case_match(
      month,
      '01' ~ 'January',
      '02' ~ 'February',
      '03' ~ 'March',
      '04' ~ 'April',
      '05' ~ 'May',
      '06' ~ 'June',
      '07' ~ 'July',
      '08' ~ 'August',
      '09' ~ 'September',
      '10' ~ 'October',
      '11' ~ 'November',
      '12' ~ 'December'
    )) |>
  select(-day) |>
  arrange(year, month) |>
  relocate(year, month)
```

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )
snp = 
  read_csv("./data/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment_df = 
  read_csv('./data/unemployment.csv') |>
  janitor::clean_names() |>
  pivot_longer(
    jan:dec,
    names_to = 'month',
    values_to = 'unemployment_percentage'
  ) |>
  mutate(
    month = case_match(
      month,
      'jan' ~ 'January',
      'feb' ~ 'February',
      'mar' ~ 'March',
      'apr' ~ 'April',
      'may' ~ 'May',
      'jun' ~ 'June',
      'jul' ~ 'July',
      'aug' ~ 'August',
      'sep' ~ 'September',
      'oct' ~ 'October',
      'nov' ~ 'November',
      'dec' ~ 'December'
    )) 
  
```

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
data_538 = 
  left_join(pols_month, snp_df, by = c('year','month')) |>
  left_join(unemployment_df, by = c('year','month'))
```

Write a short paragraph about these datasets. Explain briefly what each
dataset contained, and describe the resulting dataset (e.g. give the
dimension, range of years, and names of key variables).

- The `pols_month` dataset has 822 observations and 9 variables and
  tells us about the party affiliation distribution (democrat or
  republican) for governors and senators for a given year from years
  1947 to 2015. It also tells us whether the sitting president was a
  democrat or republican. The names of key variables are: year, month,
  gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president.
- The `snp_df` dataset has 787 observations and 3 variables, ranging
  from years 1950 to 2015. The names of key variables are: year, month,
  close.
- The `unemployment_df` dataset has 816 observations and 3 variables,
  ranging from years 1948 to 2015. The names of key variables are: year,
  month, unemployment_percentage.
- In Januarys in or after 1975 in which a democrat was president, the
  **average unemployment rate was 6.57**. The average unemployment rate
  over the same time period in which a republican was president was
  6.47.

### Problem 2

Read and clean the Mr. Trash Wheel sheet.

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  read_excel
- use reasonable variable names
- omit rows that do not include dumpster-specific data

``` r
mr_wheel = 
  read_excel('./data/202309 Trash Wheel Collection Data.xlsx', sheet = 1, range = 'A2:N586') |>
  janitor ::clean_names() |>
  mutate(year = as.numeric(year))
```

The data include a column for the (approximate) number of homes powered.
This calculation is described in the Homes powered note, but not applied
to every row in the dataset. Update the data to include a new
homes_powered variable based on this calculation.

``` r
mr_wheel = mutate(mr_wheel, homes_powered = weight_tons*500/30)
```

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to all
datasets before combining.

``` r
professor_wheel = 
  read_excel('./data/202309 Trash Wheel Collection Data.xlsx', sheet = 2, range = 'A2:M108') |>
  janitor ::clean_names() |>
  mutate(homes_powered = weight_tons*500/30) |>
  mutate(type = 'professor trash wheel')

gwynnda_wheel = 
  read_excel('./data/202309 Trash Wheel Collection Data.xlsx', sheet = 4, range = 'A2:L157') |>
  janitor ::clean_names() |>
  mutate(homes_powered = weight_tons*500/30) |>
  mutate(type = 'gwynnda trash wheel')

mr_wheel = mutate(mr_wheel, type = 'mr trash wheel')

all_wheel = 
  full_join(mr_wheel, professor_wheel) |> 
  full_join(gwynnda_wheel)
```

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of cigarette butts collected by Gwynnda in July of 2021?

- The number of observations in `mr_wheel` dataset is 584. The names of
  key variables are: dumpster, month, year, date, weight_tons,
  volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
  glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered,
  type.
- The number of observations in `professor_wheel` dataset is 106. The
  names of key variables are: dumpster, month, year, date, weight_tons,
  volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
  glass_bottles, plastic_bags, wrappers, homes_powered, type.
- The number of observations in `gwynnda_wheel` dataset is 155. The
  names of key variables are: dumpster, month, year, date, weight_tons,
  volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
  plastic_bags, wrappers, homes_powered, type.
- The total weight of trash collected by Professor Trash Wheel is 216.26
  tons. The total number of cigarette butts collected by Gwynnda in July
  of 2021 is 1.63^{4}.

### Problem 3

Import, clean, and tidy the dataset of baseline demographics. Ensure
that sex and APOE4 carrier status are appropriate encoded (i.e. not
numeric), and remove any participants who do not meet the stated
inclusion criteria (i.e. no MCI at baseline).

``` r
baseline_df = 
  read_csv('./data/MCI_baseline.csv', skip = 1) |>
  janitor::clean_names() |>
  mutate(sex = as.factor(sex)) |>
  mutate(apoe4 = as.factor(apoe4)) |>
  filter(age_at_onset > current_age | age_at_onset == '.')
```

Discuss important steps in the import process and relevant features of
the dataset. How many participants were recruited, and of these how many
develop MCI? What is the average baseline age? What proportion of women
in the study are APOE4 carriers?

- Important steps include: skipping the first row, changing data type of
  ‘sex’ and ‘apoe4’, removing rows using `filter`.
- Relevant features of the dataset: 479 participants were recruited, and
  of these 93 developed MCI. The average baseline age is 65.03. A
  proportion of 30 % of women in the study are APOE4 carriers.

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values; comment on the steps on the import process
and the features of the dataset.

``` r
amyloid_df = 
  read_csv('./data/mci_amyloid.csv', skip = 1) |>
  janitor::clean_names() |>
  rename(id = study_id) |>
  mutate_all(as.numeric)
```

Steps on the import process and the features of the dataset.

- The dataset `amyloid_df` is imported without the first row using
  arguments in `read_csv`. Then, the column name ‘study_id’ is changed
  to ‘id’ to match with the `baseline_df` dataset. The data type of all
  values in this dataset is converted to numeric uisng `mutate_all`.
  Please note that in this step, all ‘Na’ values in the original dataset
  are converted to `NA` due to coercion.
- The dateset `amyloid_df` has 487 observations and 6 variables. The
  names of variables are: id, baseline, time_2, time_4, time_6, time_8.

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings.

- A total of 8 participants appear in only the baseline dataset, and a
  total of 16 participants appear in only the amyloid dataset. It
  suggests that there are unique ‘id’ values in each dataset that are
  not shared between the two datasets.

Combine the demographic and biomarker datasets so that only participants
who appear in both datasets are retained.

``` r
combined_df <- inner_join(baseline_df, amyloid_df, by = "id")
```

Briefly describe the resulting dataset.

- The resulting dataset has 471 observations and 11 variables.

Export the result as a CSV to the data directory.

``` r
write.csv(combined_df, './data/combined_result.csv')
```
